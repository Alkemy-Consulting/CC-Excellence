"""
Holt-Winters Exponential Smoothing - Versione Corretta e Scientificamente Rigorosa
Implementazione che garantisce l'utilizzo corretto di tutti i parametri utente
e la rigorosit√† scientifica dei calcoli.
"""

import pandas as pd
import numpy as np
import streamlit as st
from typing import Tuple, Optional, Dict, Any, Union
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.stats.diagnostic import acorr_ljungbox
from statsmodels.tsa.stattools import adfuller
from scipy import stats
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
import plotly.graph_objects as go
import io
import warnings
warnings.filterwarnings('ignore')

from src.modules.utils.metrics_module import compute_all_metrics


class HoltWintersCorrected:
    """
    Implementazione corretta e scientificamente rigorosa di Holt-Winters.
    Garantisce l'utilizzo di tutti i parametri utente e la correttezza dei calcoli.
    """
    
    def __init__(self):
        self.model = None
        self.fitted_model = None
        self.training_data = None
        self.validation_data = None
        self.model_params = {}
        self.diagnostics = {}
        self.forecast_result = None
        
    def validate_input_parameters(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Validazione rigorosa dei parametri di input.
        Garantisce che tutti i parametri siano coerenti e utilizzabili.
        """
        validated = config.copy()
        
        # 1. Validazione parametri trend
        trend = validated.get('trend_type', validated.get('trend', 'add'))
        if trend not in ['add', 'mul', 'none']:
            raise ValueError(f"trend_type deve essere 'add', 'mul' o 'none', ricevuto: {trend}")
        validated['trend'] = trend
        
        # 2. Validazione parametri seasonal
        seasonal = validated.get('seasonal_type', validated.get('seasonal', 'add'))
        if seasonal not in ['add', 'mul', 'none']:
            raise ValueError(f"seasonal_type deve essere 'add', 'mul' o 'none', ricevuto: {seasonal}")
        validated['seasonal'] = seasonal
        
        # 3. Validazione coerenza trend-seasonal
        if trend == 'none' and seasonal != 'none':
            st.warning("Con trend='none', seasonal dovrebbe essere 'none' per coerenza")
        if seasonal == 'none' and validated.get('seasonal_periods', 12) != 1:
            st.warning("Con seasonal='none', seasonal_periods dovrebbe essere 1")
            
        # 4. Validazione seasonal_periods
        seasonal_periods = validated.get('seasonal_periods', 12)
        try:
            seasonal_periods = int(float(str(seasonal_periods)))
            if seasonal_periods < 1:
                raise ValueError("seasonal_periods deve essere >= 1")
            validated['seasonal_periods'] = seasonal_periods
        except (ValueError, TypeError):
            raise ValueError(f"seasonal_periods deve essere un intero >= 1, ricevuto: {seasonal_periods}")
        
        # 5. Validazione damped_trend
        damped_trend = validated.get('damped_trend', False)
        if not isinstance(damped_trend, bool):
            try:
                damped_trend = bool(damped_trend)
            except:
                damped_trend = False
        validated['damped_trend'] = damped_trend
        
        # 6. Validazione parametri smoothing (alpha, beta, gamma)
        smoothing_params = {}
        for param_name, config_key in [('alpha', 'smoothing_level'), ('beta', 'smoothing_trend'), ('gamma', 'smoothing_seasonal')]:
            # Controlla sia il nome originale che l'alias
            value = validated.get(param_name, validated.get(config_key, None))
            if value is not None:
                try:
                    value = float(str(value))
                    if not (0 <= value <= 1):
                        raise ValueError(f"{param_name} deve essere tra 0 e 1, ricevuto: {value}")
                    smoothing_params[param_name] = value
                except (ValueError, TypeError):
                    raise ValueError(f"{param_name} deve essere un float tra 0 e 1, ricevuto: {value}")
            else:
                smoothing_params[param_name] = None
                
        validated.update(smoothing_params)
        
        # 7. Validazione use_custom
        use_custom = validated.get('use_custom', False)
        if not isinstance(use_custom, bool):
            use_custom = bool(use_custom)
        validated['use_custom'] = use_custom
        
        # 8. Validazione optimized
        optimized = validated.get('optimized', True)
        if not isinstance(optimized, bool):
            optimized = bool(optimized)
        validated['optimized'] = optimized
        
        # 9. Validazione initialization_method
        init_method = validated.get('initialization_method', 'estimated')
        if init_method not in ['estimated', 'heuristic', 'known']:
            init_method = 'estimated'
        validated['initialization_method'] = init_method
        
        # 10. Validazione parametri avanzati
        for param in ['use_boxcox', 'remove_bias']:
            if param in validated:
                if not isinstance(validated[param], bool):
                    validated[param] = bool(validated[param])
            else:
                validated[param] = False
                
        return validated
    
    def prepare_data(self, data: pd.DataFrame, date_col: str, target_col: str, 
                    train_size: float = 0.8) -> Tuple[pd.Series, pd.Series]:
        """
        Preparazione rigorosa dei dati per Holt-Winters.
        Include validazione, pulizia e gestione missing values.
        """
        try:
            # 1. Validazione input
            if data.empty:
                raise ValueError("DataFrame vuoto")
            if date_col not in data.columns:
                raise ValueError(f"Colonna data '{date_col}' non trovata")
            if target_col not in data.columns:
                raise ValueError(f"Colonna target '{target_col}' non trovata")
                
            # 2. Preparazione DataFrame
            df = data.copy()
            df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
            
            # 3. Rimozione righe con date non valide
            df = df.dropna(subset=[date_col])
            if df.empty:
                raise ValueError("Nessuna data valida trovata")
                
            # 4. Ordinamento per data
            df = df.sort_values(date_col)
            
            # 5. Creazione serie temporale
            ts = df.set_index(date_col)[target_col]
            
            # 6. Validazione frequenza temporale
            if ts.index.inferred_freq is None:
                # Prova a inferire la frequenza
                freq = pd.infer_freq(ts.index)
                if freq is None:
                    # Usa frequenza giornaliera come default
                    freq = 'D'
                ts = ts.asfreq(freq)
            else:
                ts = ts.asfreq(ts.index.inferred_freq)
            
            # 7. Gestione missing values
            if ts.isnull().any():
                missing_count = ts.isnull().sum()
                st.warning(f"Trovati {missing_count} valori mancanti, applicando interpolazione lineare")
                ts = ts.interpolate(method='linear')
                
            # 8. Validazione dati sufficienti
            if len(ts) < 10:
                raise ValueError(f"Dati insufficienti: {len(ts)} punti (minimo 10 richiesti)")
                
            # 9. Split train/validation
            split_point = int(len(ts) * train_size)
            train_data = ts[:split_point]
            validation_data = ts[split_point:] if split_point < len(ts) else None
            
            self.training_data = train_data
            self.validation_data = validation_data
            
            return train_data, validation_data
            
        except Exception as e:
            st.error(f"Errore nella preparazione dati: {str(e)}")
            return None, None
    
    def fit_model(self, data: pd.Series, config: Dict[str, Any]) -> bool:
        """
        Fitting del modello Holt-Winters con utilizzo rigoroso di tutti i parametri.
        """
        try:
            # 1. Validazione parametri
            validated_config = self.validate_input_parameters(config)
            
            # 2. Estrazione parametri validati
            trend = validated_config['trend']
            seasonal = validated_config['seasonal']
            seasonal_periods = validated_config['seasonal_periods']
            damped_trend = validated_config['damped_trend']
            use_boxcox = validated_config.get('use_boxcox', False)
            remove_bias = validated_config.get('remove_bias', False)
            initialization_method = validated_config['initialization_method']
            
            # 3. Parametri smoothing
            smoothing_level = validated_config.get('alpha')
            smoothing_trend = validated_config.get('beta')
            smoothing_seasonal = validated_config.get('gamma')
            optimized = validated_config['optimized']
            
            # 4. Validazione coerenza parametri
            if trend == 'none' and seasonal == 'none':
                # Solo livello - nessun trend o stagionalit√†
                seasonal_periods = None
            elif seasonal == 'none':
                # Solo trend - nessuna stagionalit√†
                seasonal_periods = None
                smoothing_seasonal = None
            elif trend == 'none':
                # Solo stagionalit√† - nessun trend
                smoothing_trend = None
            
            # 5. Validazione dati sufficienti per stagionalit√†
            if seasonal != 'none' and seasonal_periods is not None:
                if len(data) < seasonal_periods * 2:
                    raise ValueError(f"Dati insufficienti per stagionalit√†: {len(data)} punti, "
                                   f"minimo {seasonal_periods * 2} richiesti")
            
            # 6. Creazione modello
            model_kwargs = {
                'endog': data,
                'trend': trend if trend != 'none' else None,
                'seasonal': seasonal if seasonal != 'none' else None,
                'seasonal_periods': seasonal_periods if seasonal != 'none' else None,
                'damped_trend': damped_trend,
                'initialization_method': initialization_method
            }
            
            # Aggiungi use_boxcox se supportato
            if use_boxcox:
                model_kwargs['use_boxcox'] = use_boxcox
                
            self.model = ExponentialSmoothing(**model_kwargs)
            
            # 7. Fitting del modello
            fit_kwargs = {
                'optimized': optimized,
                'remove_bias': remove_bias
            }
            
            # Aggiungi parametri smoothing se specificati
            if smoothing_level is not None:
                fit_kwargs['smoothing_level'] = smoothing_level
            if smoothing_trend is not None:
                fit_kwargs['smoothing_trend'] = smoothing_trend
            if smoothing_seasonal is not None:
                fit_kwargs['smoothing_seasonal'] = smoothing_seasonal
                
            self.fitted_model = self.model.fit(**fit_kwargs)
            
            # 8. Salvataggio parametri utilizzati con logging dettagliato
            self.model_params = {
                'trend': trend,
                'seasonal': seasonal,
                'seasonal_periods': seasonal_periods,
                'damped_trend': damped_trend,
                'use_boxcox': use_boxcox,
                'remove_bias': remove_bias,
                'initialization_method': initialization_method,
                'optimized': optimized,
                'smoothing_level': smoothing_level,
                'smoothing_trend': smoothing_trend,
                'smoothing_seasonal': smoothing_seasonal,
                'fitted_smoothing_level': self.fitted_model.params.get('smoothing_level'),
                'fitted_smoothing_trend': self.fitted_model.params.get('smoothing_trend'),
                'fitted_smoothing_seasonal': self.fitted_model.params.get('smoothing_seasonal'),
                'fitted_damping_trend': self.fitted_model.params.get('damping_trend'),
                'aic': self.fitted_model.aic,
                'bic': self.fitted_model.bic
            }
            
            # 9. Creazione log dettagliato del fitting
            self.fitting_log = self._create_fitting_log(validated_config, data)
            
            return True
            
        except Exception as e:
            st.error(f"Errore nel fitting del modello Holt-Winters: {str(e)}")
            return False
    
    def calculate_robust_mape(self, actual: np.ndarray, predicted: np.ndarray) -> float:
        """
        Calcolo robusto del MAPE che gestisce correttamente i valori zero.
        """
        actual = np.asarray(actual)
        predicted = np.asarray(predicted)
        
        # Filtra valori zero per evitare divisione per zero
        non_zero_mask = actual != 0
        
        if not np.any(non_zero_mask):
            # Se tutti i valori actual sono zero, usa SMAPE come alternativa
            return self.calculate_smape(actual, predicted)
        
        # Calcola MAPE solo sui valori non zero
        mape_values = np.abs((actual[non_zero_mask] - predicted[non_zero_mask]) / actual[non_zero_mask])
        mape = np.mean(mape_values) * 100
        
        # Controlla per valori infiniti o NaN
        if not np.isfinite(mape):
            return self.calculate_smape(actual, predicted)
            
        return float(mape)
    
    def calculate_smape(self, actual: np.ndarray, predicted: np.ndarray) -> float:
        """
        Calcolo del SMAPE (Symmetric Mean Absolute Percentage Error) come alternativa robusta al MAPE.
        """
        actual = np.asarray(actual)
        predicted = np.asarray(predicted)
        
        numerator = np.abs(actual - predicted)
        denominator = (np.abs(actual) + np.abs(predicted)) / 2
        
        # Evita divisione per zero
        non_zero_mask = denominator != 0
        if not np.any(non_zero_mask):
            return 100.0  # Massimo errore se tutti i denominatori sono zero
            
        smape_values = numerator[non_zero_mask] / denominator[non_zero_mask]
        smape = np.mean(smape_values) * 100
        
        return float(smape) if np.isfinite(smape) else 100.0
    
    def _create_fitting_log(self, config: Dict[str, Any], data: pd.Series) -> Dict[str, Any]:
        """
        Crea un log dettagliato del processo di fitting del modello Holt-Winters.
        Include tutti i parametri, ottimizzazioni e risultati.
        """
        try:
            log = {
                'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
                'data_info': {
                    'data_length': len(data),
                    'data_start': str(data.index[0]) if len(data) > 0 else 'N/A',
                    'data_end': str(data.index[-1]) if len(data) > 0 else 'N/A',
                    'data_frequency': str(data.index.inferred_freq) if data.index.inferred_freq else 'Inferred',
                    'missing_values': int(data.isnull().sum()),
                    'data_mean': float(data.mean()) if len(data) > 0 else 0,
                    'data_std': float(data.std()) if len(data) > 0 else 0,
                    'data_min': float(data.min()) if len(data) > 0 else 0,
                    'data_max': float(data.max()) if len(data) > 0 else 0
                },
                'model_configuration': {
                    'trend_type': config.get('trend', 'N/A'),
                    'seasonal_type': config.get('seasonal', 'N/A'),
                    'seasonal_periods': config.get('seasonal_periods', 'N/A'),
                    'damped_trend': config.get('damped_trend', False),
                    'initialization_method': config.get('initialization_method', 'N/A'),
                    'use_boxcox': config.get('use_boxcox', False),
                    'remove_bias': config.get('remove_bias', False),
                    'optimized': config.get('optimized', True)
                },
                'smoothing_parameters': {
                    'alpha_input': config.get('alpha', 'Auto-optimized'),
                    'beta_input': config.get('beta', 'Auto-optimized'),
                    'gamma_input': config.get('gamma', 'Auto-optimized'),
                    'alpha_optimized': self.fitted_model.params.get('smoothing_level', 'N/A') if self.fitted_model else 'N/A',
                    'beta_optimized': self.fitted_model.params.get('smoothing_trend', 'N/A') if self.fitted_model else 'N/A',
                    'gamma_optimized': self.fitted_model.params.get('smoothing_seasonal', 'N/A') if self.fitted_model else 'N/A',
                    'damping_factor': self.fitted_model.params.get('damping_trend', 'N/A') if self.fitted_model else 'N/A'
                },
                'initial_values': {
                    'initial_level': self.fitted_model.params.get('initial_level', 'N/A') if self.fitted_model else 'N/A',
                    'initial_trend': self.fitted_model.params.get('initial_trend', 'N/A') if self.fitted_model else 'N/A',
                    'initial_seasonal': self.fitted_model.params.get('initial_seasonal', 'N/A') if self.fitted_model else 'N/A'
                },
                'optimization_results': {
                    'optimization_method': 'L-BFGS-B (statsmodels default)',
                    'convergence_achieved': getattr(self.fitted_model, 'converged', 'Unknown') if self.fitted_model else 'Unknown',
                    'optimization_successful': getattr(self.fitted_model, 'success', 'Unknown') if self.fitted_model else 'Unknown',
                    'number_iterations': getattr(self.fitted_model, 'niter', 'Unknown') if self.fitted_model else 'Unknown',
                    'optimization_message': getattr(self.fitted_model, 'message', 'Unknown') if self.fitted_model else 'Unknown'
                },
                'model_performance': {
                    'aic': self.fitted_model.aic if self.fitted_model else 'N/A',
                    'bic': self.fitted_model.bic if self.fitted_model else 'N/A',
                    'log_likelihood': getattr(self.fitted_model, 'llf', 'N/A') if self.fitted_model else 'N/A',
                    'degrees_of_freedom': getattr(self.fitted_model, 'df_resid', 'N/A') if self.fitted_model else 'N/A'
                },
                'fitting_summary': {
                    'total_observations': len(data),
                    'fitted_observations': len(self.fitted_model.fittedvalues) if self.fitted_model else 0,
                    'forecast_horizon': 'User-defined',
                    'confidence_intervals': '95% (default)',
                    'seasonal_detection': 'Automatic' if config.get('seasonal') != 'none' else 'Disabled',
                    'trend_detection': 'Automatic' if config.get('trend') != 'none' else 'Disabled'
                },
                'parameter_optimization_details': {
                    'alpha_optimization': 'Minimized MSE via L-BFGS-B' if config.get('alpha') is None else 'User-specified',
                    'beta_optimization': 'Minimized MSE via L-BFGS-B' if config.get('beta') is None else 'User-specified',
                    'gamma_optimization': 'Minimized MSE via L-BFGS-B' if config.get('gamma') is None else 'User-specified',
                    'optimization_objective': 'Sum of Squared Errors (SSE)',
                    'parameter_bounds': 'All parameters constrained to [0, 1]',
                    'convergence_criteria': 'Gradient-based optimization with line search'
                },
                'model_validation': {
                    'residuals_mean': float(self.fitted_model.resid.mean()) if self.fitted_model and hasattr(self.fitted_model, 'resid') else 'N/A',
                    'residuals_std': float(self.fitted_model.resid.std()) if self.fitted_model and hasattr(self.fitted_model, 'resid') else 'N/A',
                    'residuals_skewness': float(self.fitted_model.resid.skew()) if self.fitted_model and hasattr(self.fitted_model, 'resid') else 'N/A',
                    'residuals_kurtosis': float(self.fitted_model.resid.kurtosis()) if self.fitted_model and hasattr(self.fitted_model, 'resid') else 'N/A',
                    'durbin_watson': 'N/A',  # Would need additional calculation
                    'ljung_box_pvalue': 'N/A'  # Would need additional calculation
                }
            }
            
            # Aggiungi informazioni specifiche per il tipo di modello
            if config.get('trend') == 'none' and config.get('seasonal') == 'none':
                log['model_type'] = 'Simple Exponential Smoothing (SES)'
                log['model_components'] = ['Level only']
            elif config.get('trend') != 'none' and config.get('seasonal') == 'none':
                log['model_type'] = 'Holt\'s Linear Trend Method'
                log['model_components'] = ['Level', 'Trend']
            elif config.get('trend') == 'none' and config.get('seasonal') != 'none':
                log['model_type'] = 'Exponential Smoothing with Seasonality'
                log['model_components'] = ['Level', 'Seasonality']
            else:
                log['model_type'] = 'Holt-Winters Triple Exponential Smoothing'
                log['model_components'] = ['Level', 'Trend', 'Seasonality']
            
            return log
            
        except Exception as e:
            print(f"DEBUG Holt-Winters: Error creating fitting log: {str(e)}")
            return {
                'error': f"Error creating fitting log: {str(e)}",
                'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def calculate_metrics(self) -> Dict[str, float]:
        """
        Calcolo rigoroso delle metriche di performance.
        """
        metrics = {}
        
        try:
            if self.fitted_model is None:
                return metrics
            
            # 1. Valori fitted
            fitted_values = self.fitted_model.fittedvalues
            
            # 2. Metriche in-sample
            if len(fitted_values) > 0 and self.training_data is not None:
                train_actual = self.training_data.values
                train_pred = fitted_values.values
                
                # Allineamento lunghezze
                min_len = min(len(train_actual), len(train_pred))
                train_actual = train_actual[-min_len:]
                train_pred = train_pred[-min_len:]
                
                # Calcolo metriche
                metrics['train_mae'] = float(mean_absolute_error(train_actual, train_pred))
                metrics['train_mse'] = float(mean_squared_error(train_actual, train_pred))
                metrics['train_rmse'] = float(np.sqrt(metrics['train_mse']))
                metrics['train_mape'] = self.calculate_robust_mape(train_actual, train_pred)
                metrics['train_smape'] = self.calculate_smape(train_actual, train_pred)
                
                # R¬≤
                ss_res = np.sum((train_actual - train_pred) ** 2)
                ss_tot = np.sum((train_actual - np.mean(train_actual)) ** 2)
                if ss_tot > 0:
                    metrics['train_r2'] = float(1 - (ss_res / ss_tot))
                else:
                    metrics['train_r2'] = 0.0
            
            # 3. Metriche out-of-sample (se validation data disponibile)
            if self.validation_data is not None and len(self.validation_data) > 0:
                val_forecast = self.fitted_model.forecast(len(self.validation_data))
                val_actual = self.validation_data.values
                val_pred = val_forecast.values
                
                metrics['val_mae'] = float(mean_absolute_error(val_actual, val_pred))
                metrics['val_mse'] = float(mean_squared_error(val_actual, val_pred))
                metrics['val_rmse'] = float(np.sqrt(metrics['val_mse']))
                metrics['val_mape'] = self.calculate_robust_mape(val_actual, val_pred)
                metrics['val_smape'] = self.calculate_smape(val_actual, val_pred)
                
                # R¬≤
                ss_res = np.sum((val_actual - val_pred) ** 2)
                ss_tot = np.sum((val_actual - np.mean(val_actual)) ** 2)
                if ss_tot > 0:
                    metrics['val_r2'] = float(1 - (ss_res / ss_tot))
                else:
                    metrics['val_r2'] = 0.0
            
            # 4. Metriche aggregate (per compatibilit√†)
            if 'train_mape' in metrics:
                metrics['mape'] = metrics['train_mape']
            if 'train_mae' in metrics:
                metrics['mae'] = metrics['train_mae']
            if 'train_rmse' in metrics:
                metrics['rmse'] = metrics['train_rmse']
            if 'train_r2' in metrics:
                metrics['r2'] = metrics['train_r2']
                
        except Exception as e:
            st.warning(f"Errore nel calcolo delle metriche: {str(e)}")
        
        return metrics
    
    def generate_forecast(self, periods: int, confidence_interval: float = 0.95) -> pd.DataFrame:
        """
        Generazione delle previsioni con intervalli di confidenza.
        """
        try:
            if self.fitted_model is None:
                raise ValueError("Modello deve essere addestrato prima di generare previsioni")
            
            # 1. Generazione previsioni
            forecast = self.fitted_model.forecast(periods)
            
            # 2. Calcolo intervalli di confidenza
            try:
                # Metodo moderno (statsmodels >= 0.12)
                if hasattr(self.fitted_model, 'get_prediction'):
                    pred_int = self.fitted_model.get_prediction(
                        start=len(self.training_data),
                        end=len(self.training_data) + periods - 1
                    ).summary_frame(alpha=1-confidence_interval)
                    lower_bound = pred_int['mean_ci_lower'].values
                    upper_bound = pred_int['mean_ci_upper'].values
                else:
                    # Metodo legacy
                    forecast_result = self.fitted_model.forecast(periods, return_conf_int=True)
                    if isinstance(forecast_result, tuple) and len(forecast_result) == 2:
                        forecast, conf_int = forecast_result
                        lower_bound = conf_int[:, 0]
                        upper_bound = conf_int[:, 1]
                    else:
                        # Approssimazione semplice
                        forecast_std = np.std(self.fitted_model.resid) if hasattr(self.fitted_model, 'resid') else np.std(forecast) * 0.1
                        z_score = stats.norm.ppf(1 - (1 - confidence_interval) / 2)
                        margin = z_score * forecast_std
                        lower_bound = forecast - margin
                        upper_bound = forecast + margin
            except Exception:
                # Fallback: approssimazione semplice
                forecast_std = np.std(forecast) * 0.1
                z_score = stats.norm.ppf(1 - (1 - confidence_interval) / 2)
                margin = z_score * forecast_std
                lower_bound = forecast - margin
                upper_bound = forecast + margin
            
            # 3. Conversione a array 1D
            if hasattr(forecast, 'values'):
                forecast = forecast.values
            if hasattr(lower_bound, 'values'):
                lower_bound = lower_bound.values
            if hasattr(upper_bound, 'values'):
                upper_bound = upper_bound.values
            
            # 4. Creazione DataFrame risultato
            forecast_dates = pd.date_range(
                start=self.training_data.index[-1] + pd.Timedelta(days=1),
                periods=periods,
                freq=self.training_data.index.inferred_freq or 'D'
            )
            
            forecast_df = pd.DataFrame({
                'ds': forecast_dates,
                'yhat': forecast,
                'yhat_lower': lower_bound,
                'yhat_upper': upper_bound
            })
            
            self.forecast_result = forecast_df
            return forecast_df
            
        except Exception as e:
            st.error(f"Errore nella generazione previsioni: {str(e)}")
            return pd.DataFrame()


def run_holt_winters_model(df: pd.DataFrame, date_col: str, target_col: str, horizon: int, selected_metrics: list, params: dict, return_metrics=False):
    """
    Runs the Holt-Winters model using parameters passed from the UI.
    Versione corretta che utilizza l'implementazione scientificamente rigorosa.
    """
    if not return_metrics:
        st.subheader("Holt-Winters Forecast")

    try:
        # 1. Inizializzazione modello corretto
        model = HoltWintersCorrected()
        
        # 2. Preparazione dati
        train_data, val_data = model.prepare_data(df, date_col, target_col, 0.8)
        
        if train_data is None:
            if return_metrics:
                return {}
            return None
        
        # 3. Fitting del modello
        if not model.fit_model(train_data, params):
            if return_metrics:
                return {}
            return None
        
        # 4. Generazione previsioni
        forecast_df = model.generate_forecast(horizon)
        
        if forecast_df.empty:
            if return_metrics:
                return {}
            return None
        
        # 5. Calcolo metriche
        metrics_results = model.calculate_metrics()
        
        if not return_metrics:
            st.success("Modello Holt-Winters addestrato con successo.")
            with st.expander("Vedi parametri del modello ottimizzati"):
                st.json({k: (f"{v:.4f}" if isinstance(v, float) else v) for k, v in model.model_params.items() if v is not None})

            # Calcolo e visualizzazione metriche
            st.write("### Evaluation Metrics (su dati storici)")
            if not selected_metrics: 
                selected_metrics = ["MAE", "RMSE", "MAPE"]
            
            cols = st.columns(len(selected_metrics))
            for i, metric in enumerate(selected_metrics):
                value = metrics_results.get(metric)
                if value is not None:
                    format_str = "{:.0f}%" if metric in ["MAPE", "SMAPE"] else "{:.3f}"
                    cols[i].metric(metric, format_str.format(value))

            # Grafico con Plotly
            st.write("### Grafico Forecast")
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=df[date_col], y=df[target_col], mode='lines', name='Storico', line=dict(color='#1f77b4')))
            
            # Aggiungi fitted values se disponibili
            if hasattr(model.fitted_model, 'fittedvalues'):
                fitted_values = model.fitted_model.fittedvalues
                fig.add_trace(go.Scatter(x=fitted_values.index, y=fitted_values, mode='lines', name='Fitted', line=dict(color='#ff7f0e', dash='dash')))
            
            # Aggiungi forecast
            fig.add_trace(go.Scatter(x=forecast_df['ds'], y=forecast_df['yhat'], mode='lines', name='Forecast', line=dict(color='#d62728')))
            
            # Aggiungi intervalli di confidenza
            fig.add_trace(go.Scatter(
                x=forecast_df['ds'],
                y=forecast_df['yhat_upper'],
                mode='lines',
                line=dict(color='rgba(255,0,0,0.2)'),
                showlegend=False
            ))
            fig.add_trace(go.Scatter(
                x=forecast_df['ds'],
                y=forecast_df['yhat_lower'],
                mode='lines',
                fill='tonexty',
                fillcolor='rgba(255,0,0,0.2)',
                line=dict(color='rgba(255,0,0,0.2)'),
                name='Confidence Interval'
            ))
            
            st.plotly_chart(fig, width='stretch')

            # Bottone di download
            if st.button("üì• Scarica Forecast in Excel", key="holtwinters_download_btn"):
                buffer = io.BytesIO()
                forecast_df.to_excel(buffer, index=False, engine='openpyxl')
                buffer.seek(0)
                st.download_button(
                    label="Download .xlsx",
                    data=buffer,
                    file_name="holtwinters_forecast.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

    except Exception as e:
        st.error(f"Errore durante l'esecuzione del modello Holt-Winters: {e}")
        if return_metrics:
            return {}
    
    # Restituisce le metriche se richiesto (per il modulo Exploratory)
    if return_metrics:
        return metrics_results if 'metrics_results' in locals() else {}
    
    return None  # Default per mantenere compatibilit√†


def holt_winters_forecast(
    series: pd.Series,
    forecast_periods: int = 12,
    seasonal_periods: int = 12,
    trend: str = 'add',
    seasonal: str = 'add',
    damped_trend: bool = True,
    initialization_method: str = 'estimated',
    smoothing_level: Optional[float] = None,
    smoothing_trend: Optional[float] = None,
    smoothing_seasonal: Optional[float] = None,
    optimized: bool = True
) -> Tuple[pd.Series, pd.Series, dict]:
    """
    Apply the Holt-Winters model to a time series and return fitted values,
    forecasts and model parameters.
    Versione corretta che utilizza l'implementazione scientificamente rigorosa.
    """
    try:
        # Converti parametri al formato della nuova implementazione
        config = {
            'trend': trend,
            'seasonal': seasonal,
            'seasonal_periods': seasonal_periods,
            'damped_trend': damped_trend,
            'initialization_method': initialization_method,
            'alpha': smoothing_level,
            'beta': smoothing_trend,
            'gamma': smoothing_seasonal,
            'optimized': optimized
        }
        
        # Crea DataFrame temporaneo per l'interfaccia
        temp_df = pd.DataFrame({
            'date': series.index,
            'value': series.values
        })
        
        # Esegui previsione con implementazione corretta
        model = HoltWintersCorrected()
        train_data, val_data = model.prepare_data(temp_df, 'date', 'value', 1.0)  # Usa tutti i dati per training
        
        if train_data is None:
            return pd.Series(), pd.Series(), {}
        
        if not model.fit_model(train_data, config):
            return pd.Series(), pd.Series(), {}
        
        forecast_df = model.generate_forecast(forecast_periods)
        
        if forecast_df.empty:
            return pd.Series(), pd.Series(), {}
        
        # Estrai risultati nel formato originale
        fitted_values = model.fitted_model.fittedvalues
        forecast_values = pd.Series(forecast_df['yhat'].values, index=forecast_df['ds'])
        
        # Crea dizionario parametri nel formato originale
        model_params = {
            'smoothing_level (Œ±)': model.model_params.get('fitted_smoothing_level'),
            'smoothing_trend (Œ≤)': model.model_params.get('fitted_smoothing_trend'),
            'smoothing_seasonal (Œ≥)': model.model_params.get('fitted_smoothing_seasonal'),
            'damping_trend (œï)': model.model_params.get('fitted_damping_trend'),
            'initial_level': model.fitted_model.params.get('initial_level'),
            'initial_trend': model.fitted_model.params.get('initial_trend'),
            'initial_seasonal': model.fitted_model.params.get('initial_seasonal'),
            'aic': model.fitted_model.aic,
            'bic': model.fitted_model.bic,
            'mape': model.calculate_metrics().get('mape', 0),
            'rmse': model.calculate_metrics().get('rmse', 0),
        }
        
        return fitted_values, forecast_values, model_params
        
    except Exception as e:
        st.error(f"Errore nella funzione Holt-Winters: {str(e)}")
        return pd.Series(), pd.Series(), {}


def run_holtwinters_forecast(df: pd.DataFrame, date_col: str, target_col: str,
                           model_config: Dict[str, Any], base_config: Dict[str, Any]) -> Tuple[pd.DataFrame, Dict[str, Any], Dict[str, Any]]:
    """
    Enhanced Holt-Winters forecast with proper metrics calculation.
    Versione unificata che utilizza l'implementazione ottimizzata.
    """
    try:
        # Ensure we have the required configuration
        config = {**base_config, **model_config}
        
        # Debug logging
        print(f"DEBUG Holt-Winters: Config = {config}")
        print(f"DEBUG Holt-Winters: DataFrame shape = {df.shape}")
        print(f"DEBUG Holt-Winters: Date col = {date_col}, Target col = {target_col}")
        
        # Validate seasonal periods
        seasonal_periods = config.get('seasonal_periods', 12)
        if len(df) < seasonal_periods * 2:
            error_msg = f"Insufficient data for Holt-Winters: need at least {seasonal_periods * 2} points, got {len(df)}"
            print(f"DEBUG Holt-Winters: {error_msg}")
            st.error(error_msg)
            return pd.DataFrame(), {}, {}
        
        # Initialize model
        model = HoltWintersCorrected()
        
        # Prepare data
        print("DEBUG Holt-Winters: Preparing data...")
        train_data, val_data = model.prepare_data(
            df, 
            date_col, 
            target_col,
            config.get('train_size', 0.8)
        )
        
        if train_data is None:
            error_msg = "Failed to prepare data for Holt-Winters"
            print(f"DEBUG Holt-Winters: {error_msg}")
            st.error(error_msg)
            return pd.DataFrame(), {}, {}
        
        print(f"DEBUG Holt-Winters: Data prepared - Train: {len(train_data)}, Val: {len(val_data) if val_data is not None else 0}")
        
        # Fit model
        print("DEBUG Holt-Winters: Fitting model...")
        if not model.fit_model(train_data, config):
            error_msg = "Failed to fit Holt-Winters model"
            print(f"DEBUG Holt-Winters: {error_msg}")
            st.error(error_msg)
            return pd.DataFrame(), {}, {}
        
        print("DEBUG Holt-Winters: Model fitted successfully")
        
        # Generate forecast
        print("DEBUG Holt-Winters: Generating forecast...")
        forecast_df = model.generate_forecast(
            config.get('forecast_periods', 30),
            config.get('confidence_interval', 0.95)
        )
        
        if forecast_df.empty:
            error_msg = "Failed to generate forecast"
            print(f"DEBUG Holt-Winters: {error_msg}")
            st.error(error_msg)
            return pd.DataFrame(), {}, {}
        
        print(f"DEBUG Holt-Winters: Forecast generated - Shape: {forecast_df.shape}")
        
        # Calculate metrics
        print("DEBUG Holt-Winters: Calculating metrics...")
        metrics = model.calculate_metrics()
        print(f"DEBUG Holt-Winters: Metrics calculated: {metrics}")
        
        # Create efficient visualizations
        print("DEBUG Holt-Winters: Creating visualizations...")
        plots = create_holtwinters_plots(model, forecast_df, df, date_col, target_col)
        print(f"DEBUG Holt-Winters: Created {len(plots)} plots")
        
        # Add fitting log to plots for UI display
        if hasattr(model, 'fitting_log'):
            plots['fitting_log'] = model.fitting_log
        
        print("DEBUG Holt-Winters: Forecast completed successfully")
        return forecast_df, metrics, plots
        
    except Exception as e:
        error_msg = f"Error in Holt-Winters forecasting: {str(e)}"
        print(f"DEBUG Holt-Winters: {error_msg}")
        import traceback
        print(f"DEBUG Holt-Winters: Full traceback: {traceback.format_exc()}")
        st.error(error_msg)
        return pd.DataFrame(), {}, {}


def create_holtwinters_plots(model: HoltWintersCorrected, forecast_df: pd.DataFrame, 
                           df: pd.DataFrame, date_col: str, target_col: str) -> Dict[str, Any]:
    """
    Create efficient Holt-Winters visualization plots for forecasting results.
    Optimized for maximum performance and consistency with other models.
    """
    plots = {}
    
    try:
        if forecast_df.empty or model.fitted_model is None:
            return plots
        
        # Main forecast plot (consistent with other models)
        plots['forecast_plot'] = create_main_forecast_plot(model, forecast_df, df, date_col, target_col)
        
        # Components analysis plot (if seasonal data available)
        if model.model_params.get('seasonal') != 'none' and model.model_params.get('seasonal_periods', 1) > 1:
            plots['components_plot'] = create_components_plot(model, forecast_df, target_col)
        
        # Residuals analysis plot
        plots['residuals_plot'] = create_residuals_plot(model, target_col)
        
        return plots
        
    except Exception as e:
        print(f"DEBUG Holt-Winters: Error creating plots: {str(e)}")
        return {}


def create_main_forecast_plot(model: HoltWintersCorrected, forecast_df: pd.DataFrame, 
                            df: pd.DataFrame, date_col: str, target_col: str) -> go.Figure:
    """
    Create the main forecast plot with historical data, fitted values, and forecast.
    Optimized for performance and consistency with other models.
    """
    try:
        fig = go.Figure()
        
        # Historical data
        fig.add_trace(go.Scatter(
            x=df[date_col],
            y=df[target_col],
            mode='lines',
            name='Historical Data',
            line=dict(color='#1f77b4', width=2),
            hovertemplate='<b>Historical</b><br>Date: %{x}<br>Value: %{y:.2f}<extra></extra>'
        ))
        
        # Fitted values (if available)
        if hasattr(model.fitted_model, 'fittedvalues') and not model.fitted_model.fittedvalues.empty:
            fitted_values = model.fitted_model.fittedvalues
            # Align fitted values with historical data
            if len(fitted_values) <= len(df):
                fitted_dates = df[date_col].iloc[:len(fitted_values)]
                fig.add_trace(go.Scatter(
                    x=fitted_dates,
                    y=fitted_values.values,
                    mode='lines',
                    name='Fitted',
                    line=dict(color='#ff7f0e', width=2, dash='dash'),
                    hovertemplate='<b>Fitted</b><br>Date: %{x}<br>Value: %{y:.2f}<extra></extra>'
                ))
        
        # Forecast
        fig.add_trace(go.Scatter(
            x=forecast_df['ds'],
            y=forecast_df['yhat'],
            mode='lines',
            name='Forecast',
            line=dict(color='#d62728', width=2),
            hovertemplate='<b>Forecast</b><br>Date: %{x}<br>Value: %{y:.2f}<extra></extra>'
        ))
        
        # Confidence intervals
        if 'yhat_lower' in forecast_df.columns and 'yhat_upper' in forecast_df.columns:
            # Upper bound
            fig.add_trace(go.Scatter(
                x=forecast_df['ds'],
                y=forecast_df['yhat_upper'],
                mode='lines',
                line=dict(color='rgba(214,39,40,0.2)', width=0),
                showlegend=False,
                hoverinfo='skip'
            ))
            
            # Lower bound with fill
            fig.add_trace(go.Scatter(
                x=forecast_df['ds'],
                y=forecast_df['yhat_lower'],
                mode='lines',
                fill='tonexty',
                fillcolor='rgba(214,39,40,0.1)',
                line=dict(color='rgba(214,39,40,0.2)', width=0),
                name='Confidence Interval',
                hovertemplate='<b>Confidence Interval</b><br>Date: %{x}<br>Lower: %{y:.2f}<extra></extra>'
            ))
        
        # Layout optimization
        fig.update_layout(
            title=f"Holt-Winters Forecast: {target_col}",
            xaxis_title="Date",
            yaxis_title=target_col,
            height=500,
            hovermode='x unified',
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=0.95
            ),
            xaxis=dict(
                rangeselector=dict(
                    buttons=list([
                        dict(count=30, label="1M", step="day", stepmode="backward"),
                        dict(count=90, label="3M", step="day", stepmode="backward"),
                        dict(count=180, label="6M", step="day", stepmode="backward"),
                        dict(count=365, label="1Y", step="day", stepmode="backward"),
                        dict(step="all", label="All")
                    ]),
                    x=0.02,
                    xanchor="left",
                    y=1.02,
                    yanchor="bottom"
                ),
                rangeslider=dict(visible=True),
                type="date"
            ),
            margin=dict(l=50, r=50, t=80, b=50)
        )
        
        return fig
        
    except Exception as e:
        print(f"DEBUG Holt-Winters: Error creating main forecast plot: {str(e)}")
        return go.Figure()


def create_components_plot(model: HoltWintersCorrected, forecast_df: pd.DataFrame, target_col: str) -> go.Figure:
    """
    Create components analysis plot for seasonal Holt-Winters models.
    """
    try:
        from plotly.subplots import make_subplots
        
        # Determine number of subplots based on available components
        subplot_titles = []
        if model.model_params.get('trend') != 'none':
            subplot_titles.append('Trend')
        if model.model_params.get('seasonal') != 'none':
            subplot_titles.append('Seasonality')
        if model.model_params.get('trend') != 'none':
            subplot_titles.append('Level')
        
        if not subplot_titles:
            return go.Figure()
        
        # Create subplots
        fig = make_subplots(
            rows=len(subplot_titles), 
            cols=1,
            subplot_titles=subplot_titles,
            vertical_spacing=0.1,
            shared_xaxes=True
        )
        
        row_idx = 1
        
        # Trend component
        if model.model_params.get('trend') != 'none' and 'trend' in forecast_df.columns:
            fig.add_trace(
                go.Scatter(
                    x=forecast_df['ds'], 
                    y=forecast_df['trend'],
                    mode='lines', 
                    name='Trend',
                    line=dict(color='blue', width=2),
                    showlegend=False
                ),
                row=row_idx, col=1
            )
            row_idx += 1
        
        # Seasonal component
        if model.model_params.get('seasonal') != 'none' and 'seasonal' in forecast_df.columns:
            fig.add_trace(
                go.Scatter(
                    x=forecast_df['ds'], 
                    y=forecast_df['seasonal'],
                    mode='lines', 
                    name='Seasonality',
                    line=dict(color='green', width=2),
                    showlegend=False
                ),
                row=row_idx, col=1
            )
            row_idx += 1
        
        # Level component (if trend exists)
        if model.model_params.get('trend') != 'none' and 'level' in forecast_df.columns:
            fig.add_trace(
                go.Scatter(
                    x=forecast_df['ds'], 
                    y=forecast_df['level'],
                    mode='lines', 
                    name='Level',
                    line=dict(color='orange', width=2),
                    showlegend=False
                ),
                row=row_idx, col=1
            )
        
        # Update layout
        fig.update_layout(
            height=200 * len(subplot_titles),
            title_text=f"Holt-Winters Components Analysis - {target_col}",
            showlegend=False
        )
        
        # Update axes
        fig.update_xaxes(title_text="Date", row=len(subplot_titles), col=1)
        for i in range(len(subplot_titles)):
            fig.update_yaxes(title_text=subplot_titles[i], row=i+1, col=1)
        
        return fig
        
    except Exception as e:
        print(f"DEBUG Holt-Winters: Error creating components plot: {str(e)}")
        return go.Figure()


def create_residuals_plot(model: HoltWintersCorrected, target_col: str) -> go.Figure:
    """
    Create residuals analysis plot for model diagnostics.
    """
    try:
        if not hasattr(model.fitted_model, 'resid') or model.fitted_model.resid.empty:
            return go.Figure()
        
        residuals = model.fitted_model.resid
        
        # Create subplots for residuals analysis
        from plotly.subplots import make_subplots
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('Residuals vs Time', 'Residuals Histogram', 
                          'Q-Q Plot', 'Residuals vs Fitted'),
            vertical_spacing=0.1,
            horizontal_spacing=0.1
        )
        
        # 1. Residuals vs Time
        fig.add_trace(
            go.Scatter(
                x=list(range(len(residuals))),
                y=residuals.values,
                mode='lines+markers',
                name='Residuals',
                line=dict(color='blue', width=1),
                marker=dict(size=3)
            ),
            row=1, col=1
        )
        
        # 2. Residuals Histogram
        fig.add_trace(
            go.Histogram(
                x=residuals.values,
                name='Residuals Distribution',
                nbinsx=30,
                marker_color='lightblue'
            ),
            row=1, col=2
        )
        
        # 3. Q-Q Plot (simplified)
        from scipy import stats
        qq_data = stats.probplot(residuals.dropna(), dist="norm")
        fig.add_trace(
            go.Scatter(
                x=qq_data[0][0],
                y=qq_data[0][1],
                mode='markers',
                name='Q-Q Plot',
                marker=dict(color='red', size=4)
            ),
            row=2, col=1
        )
        
        # Add theoretical line for Q-Q plot
        fig.add_trace(
            go.Scatter(
                x=qq_data[0][0],
                y=qq_data[1][1] + qq_data[1][0] * qq_data[0][0],
                mode='lines',
                name='Theoretical',
                line=dict(color='black', dash='dash')
            ),
            row=2, col=1
        )
        
        # 4. Residuals vs Fitted
        if hasattr(model.fitted_model, 'fittedvalues') and not model.fitted_model.fittedvalues.empty:
            fitted_values = model.fitted_model.fittedvalues
            min_len = min(len(residuals), len(fitted_values))
            fig.add_trace(
                go.Scatter(
                    x=fitted_values.iloc[:min_len].values,
                    y=residuals.iloc[:min_len].values,
                    mode='markers',
                    name='Residuals vs Fitted',
                    marker=dict(color='green', size=4)
                ),
                row=2, col=2
            )
        
        # Update layout
        fig.update_layout(
            height=600,
            title_text=f"Holt-Winters Residuals Analysis - {target_col}",
            showlegend=False
        )
        
        # Update axes labels
        fig.update_xaxes(title_text="Time", row=1, col=1)
        fig.update_yaxes(title_text="Residuals", row=1, col=1)
        fig.update_xaxes(title_text="Residuals", row=1, col=2)
        fig.update_yaxes(title_text="Frequency", row=1, col=2)
        fig.update_xaxes(title_text="Theoretical Quantiles", row=2, col=1)
        fig.update_yaxes(title_text="Sample Quantiles", row=2, col=1)
        fig.update_xaxes(title_text="Fitted Values", row=2, col=2)
        fig.update_yaxes(title_text="Residuals", row=2, col=2)
        
        return fig
        
    except Exception as e:
        print(f"DEBUG Holt-Winters: Error creating residuals plot: {str(e)}")
        return go.Figure()


def create_fitting_log_dropdown(fitting_log: Dict[str, Any]) -> None:
    """
    Crea un men√π a tendina con il log completo del fitting dei parametri Holt-Winters.
    """
    try:
        if not fitting_log or 'error' in fitting_log:
            st.warning("‚ö†Ô∏è Fitting log non disponibile")
            return
        
        with st.expander("üîß **Log Completo Fitting Parametri Holt-Winters**", expanded=False):
            
            # Header con timestamp
            st.markdown(f"**üìÖ Timestamp:** {fitting_log.get('timestamp', 'N/A')}")
            st.markdown(f"**ü§ñ Tipo Modello:** {fitting_log.get('model_type', 'N/A')}")
            st.markdown(f"**üß© Componenti:** {', '.join(fitting_log.get('model_components', []))}")
            
            # Tabs per organizzare le informazioni
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "üìä Dati", "‚öôÔ∏è Configurazione", "üéØ Ottimizzazione", 
                "üìà Performance", "üîç Validazione"
            ])
            
            with tab1:
                st.markdown("### üìä Informazioni sui Dati")
                data_info = fitting_log.get('data_info', {})
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("Lunghezza Dati", f"{data_info.get('data_length', 'N/A')}")
                    st.metric("Valori Mancanti", f"{data_info.get('missing_values', 'N/A')}")
                    st.metric("Media", f"{data_info.get('data_mean', 0):.2f}")
                    st.metric("Deviazione Standard", f"{data_info.get('data_std', 0):.2f}")
                
                with col2:
                    st.metric("Data Inizio", data_info.get('data_start', 'N/A'))
                    st.metric("Data Fine", data_info.get('data_end', 'N/A'))
                    st.metric("Frequenza", data_info.get('data_frequency', 'N/A'))
                    st.metric("Min-Max", f"{data_info.get('data_min', 0):.2f} - {data_info.get('data_max', 0):.2f}")
            
            with tab2:
                st.markdown("### ‚öôÔ∏è Configurazione Modello")
                config = fitting_log.get('model_configuration', {})
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown(f"**Tipo Trend:** {config.get('trend_type', 'N/A')}")
                    st.markdown(f"**Tipo Stagionalit√†:** {config.get('seasonal_type', 'N/A')}")
                    st.markdown(f"**Periodi Stagionali:** {config.get('seasonal_periods', 'N/A')}")
                    st.markdown(f"**Trend Smorzato:** {config.get('damped_trend', 'N/A')}")
                
                with col2:
                    st.markdown(f"**Metodo Inizializzazione:** {config.get('initialization_method', 'N/A')}")
                    st.markdown(f"**Box-Cox:** {config.get('use_boxcox', 'N/A')}")
                    st.markdown(f"**Rimuovi Bias:** {config.get('remove_bias', 'N/A')}")
                    st.markdown(f"**Ottimizzato:** {config.get('optimized', 'N/A')}")
            
            with tab3:
                st.markdown("### üéØ Dettagli Ottimizzazione")
                
                # Parametri smoothing
                st.markdown("#### üìâ Parametri Smoothing")
                smoothing = fitting_log.get('smoothing_parameters', {})
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.markdown(f"**Alpha (Œ±):**")
                    st.markdown(f"  - Input: {smoothing.get('alpha_input', 'N/A')}")
                    st.markdown(f"  - Ottimizzato: {smoothing.get('alpha_optimized', 'N/A')}")
                
                with col2:
                    st.markdown(f"**Beta (Œ≤):**")
                    st.markdown(f"  - Input: {smoothing.get('beta_input', 'N/A')}")
                    st.markdown(f"  - Ottimizzato: {smoothing.get('beta_optimized', 'N/A')}")
                
                with col3:
                    st.markdown(f"**Gamma (Œ≥):**")
                    st.markdown(f"  - Input: {smoothing.get('gamma_input', 'N/A')}")
                    st.markdown(f"  - Ottimizzato: {smoothing.get('gamma_optimized', 'N/A')}")
                
                # Valori iniziali
                st.markdown("#### üöÄ Valori Iniziali")
                initial = fitting_log.get('initial_values', {})
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.markdown(f"**Livello Iniziale:** {initial.get('initial_level', 'N/A')}")
                with col2:
                    st.markdown(f"**Trend Iniziale:** {initial.get('initial_trend', 'N/A')}")
                with col3:
                    st.markdown(f"**Stagionalit√† Iniziale:** {initial.get('initial_seasonal', 'N/A')}")
                
                # Risultati ottimizzazione
                st.markdown("#### üîÑ Risultati Ottimizzazione")
                opt_results = fitting_log.get('optimization_results', {})
                opt_details = fitting_log.get('parameter_optimization_details', {})
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown(f"**Metodo:** {opt_results.get('optimization_method', 'N/A')}")
                    st.markdown(f"**Convergenza:** {opt_results.get('convergence_achieved', 'N/A')}")
                    st.markdown(f"**Successo:** {opt_results.get('optimization_successful', 'N/A')}")
                
                with col2:
                    st.markdown(f"**Iterazioni:** {opt_results.get('number_iterations', 'N/A')}")
                    st.markdown(f"**Obiettivo:** {opt_details.get('optimization_objective', 'N/A')}")
                    st.markdown(f"**Vincoli:** {opt_details.get('parameter_bounds', 'N/A')}")
            
            with tab4:
                st.markdown("### üìà Performance del Modello")
                performance = fitting_log.get('model_performance', {})
                summary = fitting_log.get('fitting_summary', {})
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("AIC", f"{performance.get('aic', 'N/A')}")
                    st.metric("BIC", f"{performance.get('bic', 'N/A')}")
                    st.metric("Log-Likelihood", f"{performance.get('log_likelihood', 'N/A')}")
                
                with col2:
                    st.metric("Gradi di Libert√†", f"{performance.get('degrees_of_freedom', 'N/A')}")
                    st.metric("Osservazioni Totali", f"{summary.get('total_observations', 'N/A')}")
                    st.metric("Osservazioni Fitted", f"{summary.get('fitted_observations', 'N/A')}")
            
            with tab5:
                st.markdown("### üîç Validazione del Modello")
                validation = fitting_log.get('model_validation', {})
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("#### üìä Statistiche Residui")
                    st.markdown(f"**Media:** {validation.get('residuals_mean', 'N/A')}")
                    st.markdown(f"**Deviazione Standard:** {validation.get('residuals_std', 'N/A')}")
                    st.markdown(f"**Skewness:** {validation.get('residuals_skewness', 'N/A')}")
                
                with col2:
                    st.markdown("#### üìà Altri Test")
                    st.markdown(f"**Kurtosis:** {validation.get('residuals_kurtosis', 'N/A')}")
                    st.markdown(f"**Durbin-Watson:** {validation.get('durbin_watson', 'N/A')}")
                    st.markdown(f"**Ljung-Box p-value:** {validation.get('ljung_box_pvalue', 'N/A')}")
                
                # Riepilogo fitting
                st.markdown("#### üìã Riepilogo Fitting")
                st.markdown(f"**Rilevamento Stagionalit√†:** {summary.get('seasonal_detection', 'N/A')}")
                st.markdown(f"**Rilevamento Trend:** {summary.get('trend_detection', 'N/A')}")
                st.markdown(f"**Intervalli di Confidenza:** {summary.get('confidence_intervals', 'N/A')}")
            
            # Download del log
            st.markdown("---")
            if st.button("üì• Scarica Log Fitting (JSON)", key="holtwinters_log_download"):
                import json
                import io
                
                log_json = json.dumps(fitting_log, indent=2, ensure_ascii=False)
                buffer = io.BytesIO()
                buffer.write(log_json.encode('utf-8'))
                buffer.seek(0)
                
                st.download_button(
                    label="Download Log JSON",
                    data=buffer,
                    file_name=f"holtwinters_fitting_log_{fitting_log.get('timestamp', 'unknown').replace(':', '-').replace(' ', '_')}.json",
                    mime="application/json"
                )
        
    except Exception as e:
        st.error(f"Errore nella visualizzazione del log fitting: {str(e)}")
        print(f"DEBUG Holt-Winters: Error displaying fitting log: {str(e)}")
